---
title: "Trabajo Curso Series de Tiempo"
author: "Eduardo Contreras Bohórquez"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, echo=FALSE, message=FALSE, warning=FALSE)
```

```{r, results='hide'}
library(readxl)
library(forecast)
library(tseries)
library(forecast)
library(lmtest)
library(CombMSC)
library(tsoutliers)

dat <- read_excel("Base_Accidentes.xlsx")
myts <- ts(dat$HER, start=c(2005,1),end=c(2018,7),frequency=12)
```

# Estadísticas descriptivas

Serie de tiempo del número de heridos en la base de datos de accidentes. 163 registros mensuales desde enero de 2005 hasta julio de 2018.

```{r}
plot(myts, ylab="Número de heridos")
```

# Transformación Box-Cox para estabilizar la varianza

Aunque en la serie original no se observa un problema de heterocedasticidad severo, se aplicó la transformación BoxCox con el parámetro lambda = 2 obtenido a través del método BoxCox.lambda de R.

```{r}
mytsBC2 <- forecast::BoxCox(myts,lambda=2) #Lambda obtenido con R
plot(mytsBC2)
```



# Descomposición de la serie

El diagrama de autocorrelación muestra que se presenta una asociación estadística entre el numero de heridos en el tiempo t, y los heridos a un rezago de tiempo h, esto se presenta inclusive a rezagos de más de 5 años como se observa en la gráfica.

```{r}
acf(mytsBC2, lag=60, main="autocorrelación")
```

Se aplica diferenciación para remover la tendencia y estacionaliad de la serie. 

```{r}
dmytsBC2 <- diff(mytsBC2)
acf(dmytsBC2, lag=60, main="ACF Diferenciación ordinaria")
```


```{r}
DdmytsBC2 <- diff(diff(mytsBC2), lag=12)
acf(DdmytsBC2, lag=60, main="ACF Diferenciación estacional")
```

# Pruebas de raíces unitarias

El test de Dickey-Fuller de raíces unitarias sobre la serie que ha pasado por los procesos de estabilización de la varianza y diferenciación para remover tendencia y estacionalidad, indica que la componente restante es estacionaria con un nivel de confianza del 95%.

```{r, results='hide'}
adf.test(DdmytsBC2)
```

```{r}
plot(DdmytsBC2)
```

# Postulación de modelos ARIMA

- A partir del diagrama de autocorrelación simple se postula el modelo de Promedios móviles puro MA(1).
- Mediante diagrama de autocorrelación parcial se postula el modelo Autorregresivo puro AR(2).
- Con la función auto.arima de R, restringiendo los órdenes ordinarios max.p=2, max.q=1, y estacionales max.P=2 y max.Q=1 (de acuerdo a los correlogramas), se obtuvo el modelo ARIMA(1,0,0)(2,0,0)[12] con media distinta de 0.

```{r}
acf(DdmytsBC2, lag=60, ci.type="ma", main="")
pacf(DdmytsBC2, lag=60, main="")
```

```{r, eval=F}
m <- auto.arima(myts,
                d=1,D=1,
                max.p=2,max.q=1,max.P=2,max.Q=1,
                start.p=0,start.q=0,start.P=0,start.Q=0,
                stationary=TRUE,seasonal=TRUE,ic='bic',test='adf',
                lambda=2)
coeftest(m)
m
```

# Ajuste de modelos ARIMA

En la siguiente tabla se puede ver resumido todos los modelos ajustados, así como las métricas BIC, Raiz del Error Cuadratico Medio (RECM), y la validación de supuestos sobre los residuales.

TABLA RESULTADOS!!!!!

# Resultados

El modelo seleccionado es ARIMA(1,0,0)(2,0,0)[12] con BoxCox.lamda=2 y con modelamiento de outliers. Este modelo a pesar de no tener el BIC más bajo, tiene un RECM bajo y todos los supuestos sobre los residuales se cumplen.

```{r }
m <- Arima(myts, order=c(1,0,0), seasonal=list(order=c(2,0,0), period=12), include.mean=T, lambda=2, method="CSS-ML", xreg=NULL)

## Outliers
modelo <- m
resi = residuals(modelo)
coef = coefs2poly(modelo)
outs = locate.outliers(resi,coef)
n = length(myts)
xreg = outliers.effects(outs, n)

####Estimación del modelo con variables regresoras en funcion Arima
mo <- Arima(myts, order=c(1,0,0), seasonal=list(order=c(2,0,0), period=12), include.mean=T, lambda=2, method="CSS-ML", xreg=xreg)
```

## Pronósticos
```{r}
Pronosticos=forecast(mo, h=12,level=0.95, xreg=xreg)
plot(Pronosticos)
```

##Validación de supuestos sobre los residuales

```{r}
# VALIDAR SUPUESTOS SOBRE LOS RESIDUALES DEL MODELO
modelo <- mo
residuales <- modelo$residuals

#1. Normalidad (H0:normalidad) 
#jarque.bera.test(residuales)
plot(density(residuales), main="Normailidad")

#2. No autocorrelación (H0: independencia)
#Box.test(residuales, lag = (length(residuales)/4), type = "Ljung-Box", fitdf = 2)
acf(residuales, lag = 36, main="No autocorrelación")
#pacf(residuales)

#3. Varianza constante
###Estadíticas CUSUM
res=residuales
cum=cumsum(res)/sd(res)
N=length(res)
cumq=cumsum(res^2)/sum(res^2)
Af=0.948 ###Cuantil del 95% para la estadistica cusum
co=0.12672 ####Valor del cuantil aproximado para cusumsq para n/2=200
LS=Af*sqrt(N)+2*Af*c(1:length(res))/sqrt(N)
LI=-LS
LQS=co+(1:length(res))/N
LQI=-co+(1:length(res))/N
plot(cum,type="l",ylim=c(min(LI),max(LS)),xlab="t",ylab="",main="CUSUM")
lines(LS,type="S",col="red")
lines(LI,type="S",col="red")
#CUSUM Square
plot(cumq,type="l",xlab="t",ylab="",main="CUSUMSQ")                      
lines(LQS,type="S",col="red")       
lines(LQI,type="S",col="red")

#4. Valor esperado es 0 (H0:mu = 0)
#t.test(residuales, mu=0, alternative = "two.sided")
#wilcox.test(residuales, mu=0, alternative = "two.sided") #non parametric
plot(residuales, main="Media es 0")
abline(h=0, col="blue")
```

## Rolling

```{r}
# ROLLING
serie <- myts
n <- length(serie)
init <- as.integer(n*0.7)

reals <- list()
preds <- list()
for (k in init:n-1) {
    split <- splitTrainTest(serie, numTrain=k)
    train <- split$train
    real <- split$test[1]
    reals <- c(reals, real)
    
    refit <- Arima(train, order=c(1,0,0), seasonal=list(order=c(2,0,0), period=12), include.mean=T, lambda=2, method="CSS-ML", xreg=NULL)

    pred <- forecast(refit, h=1)$mean
    preds <- c(preds, pred)
 
}

df <- data.frame(real=unlist(reals), pred=unlist(preds))

#Root Mean Squared Error
RECM <- sqrt(mean((df$real - df$pred)**2))

plot(df$real, type='l', main="Rolling (30% test)", sub=paste("RECM:",RECM))
lines(df$pred, col="blue")
```



## Modelo con menor RECM

El modelo con menor RECM es ARIMA(1,1,0)(2,1,0)[12] con BoxCox.lamda = 3.172689. Dicho valor de lamnda fue seleccionado por el procedimiento homologo en Python. 

A continuación se presentan los pronósticos y el Rolling.

```{r }
m <- Arima(myts, order=c(1,1,0), seasonal=list(order=c(2,1,0), period=12), include.mean=T, lambda=3.1726891131745796, method="CSS-ML", xreg=NULL)

Pronosticos=forecast(m,h=12,level=0.95)
plot(Pronosticos)
```

```{r}
# ROLLING
serie <- myts
n <- length(serie)
init <- as.integer(n*0.7)

reals <- list()
preds <- list()
for (k in init:n-1) {
    split <- splitTrainTest(serie, numTrain=k)
    train <- split$train
    real <- split$test[1]
    reals <- c(reals, real)
    
    refit <- Arima(train, order=c(1,1,0), seasonal=list(order=c(2,1,0), period=12), include.mean=T, lambda=3.1726891131745796, method="CSS-ML", xreg=NULL)

    pred <- forecast(refit, h=1)$mean
    preds <- c(preds, pred)
}

df <- data.frame(real=unlist(reals), pred=unlist(preds))

#Root Mean Squared Error
RECM <- sqrt(mean((df$real - df$pred)**2))

plot(df$real, type='l', main="Rolling (30% test)", sub=paste("RECM:",RECM))
lines(df$pred, col="blue")
```































